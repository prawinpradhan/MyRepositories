qplot(wt,mpg,shape=factor(cyl), color = factor(am) ,data = mtcars,xlab="Weight of the Car(lb/1000)",ylab="Miles per Gallon") + aes(size=4)+scale_size_identity(guide="none")
qplot(wt,mpg,shape=factor(cyl), color = factor(am) ,data = mtcars,xlab="Weight of the Car(lb/1000)",ylab="Miles per Gallon") + aes(size=4)+scale_size_identity(guide="none")+scale_colour_manual(name = "Transmission",labels=c("Automatic","Manual"))
qplot(wt,mpg,shape=factor(cyl), color = factor(am) ,data = mtcars,xlab="Weight of the Car(lb/1000)",ylab="Miles per Gallon") + aes(size=4)+scale_size_identity(guide="none")+scale_colour_manual(name = "Transmission",labels=c("Automatic","Manual"),values = c("blue", "red",)
qplot(wt,mpg,shape=factor(cyl), color = factor(am) ,data = mtcars,xlab="Weight of the Car(lb/1000)",ylab="Miles per Gallon") + aes(size=4)+scale_size_identity(guide="none")+scale_colour_manual(name = "Transmission",labels=c("Automatic","Manual"),values = c("blue", "red"))
qplot(wt,mpg,shape=factor(cyl), color = factor(am) ,data = mtcars,xlab="Weight of the Car(lb/1000)",ylab="Miles per Gallon") + aes(size=4)+scale_size_identity(guide="none")+scale_colour_manual(name = "Transmission",labels=c("Automatic","Manual"),values = c("blue", "red")) + scale_shape_identity(name = "Number of Cylnders",labels=c(4,6,8),values = c(17,18,19))
qplot(wt,mpg,shape=factor(cyl), color = factor(am) ,data = mtcars,xlab="Weight of the Car(lb/1000)",ylab="Miles per Gallon") + aes(size=4)+scale_size_identity(guide="none")+scale_colour_manual(name = "Transmission",labels=c("Automatic","Manual"),values = c("blue", "red")) + scale_shape_manual(name = "Number of Cylnders",labels=c(4,6,8),values = c(17,18,19))
qplot(wt,mpg,shape=factor(cyl), color = factor(am) ,data = mtcars,xlab="Weight of the Car(lb/1000)",ylab="Miles per Gallon") + aes(size=4)+scale_size_identity(guide="none")+scale_colour_manual(name = "Transmission",labels=c("Automatic","Manual"),values = c("blue", "red")) + scale_shape_manual(name = "Number of Cylnders",labels=c(4,6,8),values = c(17,18,20))
qplot(wt,mpg,shape=factor(cyl), color = factor(am) ,data = mtcars,xlab="Weight of the Car(lb/1000)",ylab="Miles per Gallon") + aes(size=4)+scale_size_identity(guide="none")+scale_colour_manual(name = "Transmission",labels=c("Automatic","Manual"),values = c("blue", "red")) + scale_shape_manual(name = "Number of Cylnders",labels=c(4,6,8),values = c(17,18,21))
plot(optimised_model)
qplot(optimised_model)
plot(optimised_model)
plot(predict(optimised_model))
lines(predict(optimised_model))
qplot(wt,mpg,shape=factor(cyl), color = factor(am) ,data = mtcars,xlab="Weight of the Car(lb/1000)",ylab="Miles per Gallon") + aes(size=4)+scale_size_identity(guide="none")+scale_colour_manual(name = "Transmission",labels=c("Automatic","Manual"),values = c("blue", "red")) + scale_shape_manual(name = "Number of Cylnders",labels=c(4,6,8),values = c(17,18,21))+lines(predict(optimised_model))
xCoeff
summary(am_model_fit)
data(iris)
library(ggplot2)
names(iris)
table(iris$Species)
library(caret)
library(kernlab)
inTrain <- createDataPartition(y=iris$Species,p=0.7,list=False)
inTrain <- createDataPartition(y=iris$Species,p=0.7,list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training)
dim(testing)
qplot(Petal.Width,Sepal.Width,colour=Species,data=iris)
modFit <- train(Species ~ . ,method="rpart",data=training)
print(modFit$FinalModel)
modFit <- train(Species ~ . ,method="rpart",data=training)
print(modFit$FinalModel)
print(modFit$finalModel)
names(training)
plot(modFit$finalModel,uniform=TRUE,main="Classification Tree")
text(modFit$finalModel,use.n=TRUE,all=TRUE,cex=.8)
library(rattle)
install.packages("rattle")
fancyRpartPlot(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages(rpart.plot)
install.packages("rpart.plot")
library(rpart.plot)
install.packages("rpart.plot")
install.packages("rpart.plot")
fancyRpartPlot(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
predict(modFit,newdata=testing)
library(ElemStatLearn)
install.packages(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(ozone)
head(ozone)
ozone[order(ozone),]
ozone <- ozone[order(ozone),]
dim(ozone[1])
dim(ozone[1])
1:dim(ozone[1])
1:dim(ozone[1])
dim(ozone[1])
ll <- matrix(NA,rnum=10,ncol=155)
ll <- matrix(NA,nrow=10,ncol=155)
for(i in 1:10){}
for(i in 1:10){
ss <- sample(1:dim(ozone)[1],replace=T)
ozone0 <- ozone[ss,];ozone0<-ozone0[order(ozone$ozone),]
loess0 <- loess(temperature ~ ozone ,data = ozone0,span=0.2)
ll[i,] <- predict(loess0,newdata=data.frame(ozone=1:155))
}
plot(ozone$ozone,ozone$temperature,pch=19,cex=0.5)
for(i in 1:10){lines(1:155,ll[i,],col="grey",lwd=2)}
lines(1:155,apply(ll,2,mean),col="red",lwd=2)
dim(ozone)[1]
?sample
?apply
ll
dim(ll)
ctreeBag$fit
library(caret)
ctreeBag$fit
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
inTrain <- createDataPartition(segmentationOriginal$Case,p=0.7,list = FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training);dim(testing)
finalModel <- train(Case ~ . , model = "rpart",data=training)
install.packages("randomForest")
install.packages("randomForest")
finalModel <- train(Case ~ . , model = "rpart",data=training)
library(randomForest)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(segmentationOriginal$Case,p=0.7,list = FALSE)
training <- segmentationOriginal[inTrain,]
set.seed(125)
finalModel <- train(Case ~ . , model = "rpart",data=segmentationOriginal)
set.seed(125)
dim(training)
dim(testing)
finalModel <- train(Case ~ . , model = "rpart",data=training)
finalModel
exit
gc()
gc()
library(doMC)
install.packages("doMC")
install.packages("doParallel")
library(doParallel)
cl<-makeCluster(detectCores())
registerDoParallel(cl)
cl
gc()
library(quantmod)
from.dat <- as.Date("01/01/08", format="%m/%d/%y")
to.dat <- as.Date("12/31/13", format="%m/%d/%y")
getSymbols("GOOG", src="google", from = from.dat, to = to.dat)
head(GOOG)
dim(GOOG)
mGoog <- to.monthly(GOOG)
googOpen <- Op(mGoog)
ts1 <- ts(googOpen,frequency=12)
plot(ts1,xlab="Years+1", ylab="GOOG")
mGoog <- to.monthly(GOOG)
names(GOOG)
install.packages("xts")
install.packages("xts")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
names(vowel.train)
training <- data.frame(y=factor(vowel.train$y),vowel.train[-y,])
training <- data.frame(y=factor(vowel.train$y),vowel.train[,-y])
names(training)
class(training$y)
testing <- data.frame(y=factor(vowel.test$y),vowel.test[,-y])
set.seed(33833)
library(doparallel)
library(doParallel)
detectCores()
c1<-makeCluster(detectCores())
?registerDoParallel
registerDoParallel(c1)
library(caret)
library(rf)
library(rpart)
modrf <- train(y ~ .,data=training,method="rf",prox=TRUE)
?save
modrf <- save(modrf)
save(modrf,modrf)
save(modrf,file=modrf)
save(modrf,file="modrf.RData")
modgbm <- train(y ~ . , data= training,method="gbm",verbose="FALSE")
modgbm <- train(y ~ . , data= training,method="gbm",verbose="FALSE")
save(modgbm,file="modgbm.RData")
confusionMatrix(predict(modrf,newdata=testing),testing$y)
confusionMatrix(predict(modrbm,newdata=testing),testing$y)
confusionMatrix(predict(modgbm,newdata=testing),testing$y)
set.seed(33833)
modgbm <- train(y ~ . , data= training,method="gbm",verbose="FALSE")
confusionMatrix(predict(modgbm,newdata=testing),testing$y)
confusionMatrix(predict(modgbm,newdata=testing),predict(modrf,newdata=testing))
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(training)
modRf <- train(diagnosis ~ .,data=training,method="rf",prox=TRUE)
modGbm <- train(diagnosis ~ .,data=training,method="gbm",verbose=FALSE)
modLda <- train(diagnosis ~ .,data=training,method="lda")
testRf <- predict(modRf,newdata=testing)
testGbm <- predict(modGbm,newdata=testing)
testLda <- predict(modLda,newdata=testing)
newData <- data.frame(testRf,testGbm,testLda,diagnosis=testing$diagnosis)
comModRf <- train( diagnosis ~ .,method = "rf",data=newData)
newPrediction <- predict(comModRf,newdata=testing)
confusionMatrix(newPrediction,testing$diagnosis)[[1]]
confusionMatrix(newPrediction,testing$diagnosis)[[2]]
confusionMatrix(newPrediction,testing$diagnosis)[[3]]
confusionMatrix(testRf,testing$diagnosis)[[3]][1]
confusionMatrix(testLda,testing$diagnosis)[[3]][1]
confusionMatrix(testGbm,testing$diagnosis)[[3]][1]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
?plot.enet
??plot.enet
?lasso
library(caret)
?lasso
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
names(training)
install.packages("lasso")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
modFit <- train(CompressiveStrength ~ .,data=training,method="lasso")
print(modFit)
summary(modFit)
modFit$penalty
modFit[1]
modFit[1]2
modFit[2]
str(modFit)
names(modFit)
modFit$coefnames
names(training)
modFit$finalModel
?lasso
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
dat = read.csv("C:/Users/Prawin/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("forecast")
?bats
?bats()
?ets
ets1 <- ets(testing,model=bats())
?forecast
library(forecast)
?ets
?bats()
names(training)
fit <- bats(training)
fit <- bats(training$visitsTumblr)
?forecast
fcast <- forecast(fit)
plot(fcast); lines(testing,col="red")
accuracy(fcast,testing)
accuracy(fcast,testing$visitsTumblr)
plot(fcast); lines(testing$visitsTumblr,col="red")
plot(fcast); lines(testing,col="red")
fcast
testing
length(fcast)
fit <- bats(training)
training
fit <- bats(training$visitsTumblr)
length(fit)
fit
?forecast
fcast<- forecast(fit)
fit$model
fcast$model
fcast
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
install.packages("e1071")
install.packages("e1071")
install.packages("e1071")
library(e1071)
library(doParellel)
library(doParallel)
registerDoParallel(2)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(care)
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
?svm
modFit <- train(CompressiveStrength ~ . , method = "svm",data=training)
names(training)
set.seed(325)
modFit <- svm(CompressiveStrength ~ .,data=training)
modFit
op <- predict(modFit,newData=testing)
ConfusionMatrix(op,testing$CompressiveStrength)
confusionMatrix(op,testing$CompressiveStrength)
op
op,testing$CompressiveStrength
testing$CompressiveStrength
predict(modFit,newData=testing)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
modSVM <- svm(CompressiveStrength ~ . ,data=training)
predict(modSVM,testing)
ConfusionMatrix(predict(modSVM,testing),testing$CompressiveStrength)
confusionMatrix(predict(modSVM,testing),testing$CompressiveStrength)
accuracy(predict(modSVM,testing),testing$CompressiveStrength)
library(forecast)
accuracy(predict(modSVM,testing),testing$CompressiveStrength)
gc()
?gc
swirl()
library(swirl)
ls()
rm(list=ls())
swirl()
library(swirl)
swirl()
lm(child ~ parent,data=galton)
fit <- lm(child ~ parent,data=galton)
fit <- lm(child ~ parent,galton)
summary(fit)
fit$residuals
mean(fit$residuals)
cov(fit$residuals,galton$parent)
sys.time()
Sys.time()
p<-Sys.time()
p$sec
?unclass
x<-unclass(p)
p$sec
x<-as.POSIXlt(p)
x<-unclass(x)
x$sec
x <- as.Date("2012-03-01") y <- as.Date("2012-02-28")
x-y
## Time difference of 2 days
x <- as.POSIXct("2012-10-25 01:00:00")
y <- as.POSIXct("2012-10-25 06:00:00", tz = "GMT")
y-x
message
?message
traceback()
1/0
date
date()
date()/2
traceback()
mean(x)
mean(y)
mean(yq)
traceback()
debug(lm)
lm(yy ~ xx)
x <- matrix(1:9,3,3)
apply(x,2,mean)
x <- list(1:10,rnorm(5))
x
x <- list(1:10,rnorm(5))
lapply(x,mean)
lapply(x,count)
lapply(x,length)
lapply(x,runif)
?runif
sapply(x,runif)
sapply(x,mean)
sapply(x,mean)[1]
lapply(x,mean)[1]
?mapply
lapply(rep,1:4,4:1)
mapply(rep,1:4,4:1)
mapply(rep,1:4,4:1,2)
mapply(rep,1:4,4:1,1)
system.time(readLines("https://inkolm04.tcs.com"))
?Rprof
getdir()
getwd()
search()
GlobalEnv()
search().GlobalEnv
rnorm(100,2,2)
x <- rnorm(100,2,2)
summary(r)
summary(x)
x <- rpois(10,1)
summary(x)
x <- rpois(10,1:10)
plot(x,1:10)
?plot
plot(x,1:10,type=l)
plot(x,1:10,type="l")
x <- rpois(14,1:1000)
plot(x,-500:500,type=l)
plot(x,-500:499,type=l)
plot(x,1:1000,type=l)
length(x)
x <- rpois(1000:17)
?rpois
x <- rpois(1000,17)
length(x)
plot(x,1:1000,type=l)
plot(x,1:1000,type="l")
plot(1:1000,x,type="l")
summary(x)
rnorm(10,c(0,1))
?binomial
rpois(10,c(0,1))
?rbinom
rbinom(10,1,prob=.5)
rbinom(10,2,prob=.5)
rbinom(10,8,prob=.5)
rbinom(10,1,prob=.5)
x <- rbinom(10,8,prob=.5)
sum(x)
x <- rbinom(10,1,prob=.5)
sum(x)
x <- rbinom(10,1,prob=.5)
sum(x)
x
x <- rbinom(100,1,prob=.5)
sum(x)/length(x)
x
sum(x)/length(x)
x <- rbinom(100,1,prob=.5)
sum(x)/length(x)
x <- rbinom(100000,1,prob=.5)
sum(x)/length(x)
x <- rbinom(100000,1,prob=.5)
sum(x)/length(x)
x <- rbinom(100000,1,prob=.5)
sum(x)/length(x)
?gl
library(dataset)
library(datasets)
head(airquality)
split(airquality,airquality$Month)
head(split(airquality,airquality$Month)[1])
head(split(airquality,airquality$Month)[2])
x <- matrix(1:6, 2, 3)
x[1,2]
x[1,2,drop=F]
?complete.cases
?tapply
setwd("C:\Users\Prawin\DataScienceCapstone\WordPredictor")
setwd("C:\\Users\\Prawin\\DataScienceCapstone\\WordPredictor")
loadRDS("./data//")
loadRDS("./data//*")
readRDs("./data//")
readRDS("./data//")
readRDS("./data//BiDF.rds")
readRDS("./data//QuadDF.rds")
readRDS("./data//TriDF.rds")
QuadDF <- readRDS("data/QuadDF.rds")
TriDF <- readRDS("data/TriDF.rds")
BiDF <- readRDS("data/BiDF.rds")
test <- QuadDF
test[1]
test[1,1]
class(test)
names(test)
test[test$Prediction == ass ]
test[test$Prediction == "ass" ]
test[test$Prediction == "ass", ]
test[test$Prior == "*ass*", ]
test[test$Prior == "*strip*", ]
grep(x=test$Prior,pattern="*ass*",value=T)
grep(x=test$Prior,pattern="*abbot*",value=T)
grep(x=test$Prior,pattern="*ass*",value=T)
grep(x=test$Prior,pattern="ass",value=T)
grep(x=test$Prior,pattern="^ass$",value=T)
profane <- c("ass","bitch")
grep(x=test$Prior,pattern not in profane ,value=T)
grep(x=test$Prior,pattern <> profane ,value=T)
grep(x=test$Prior,pattern != profane ,value=T)
test[test$Predict != profane,]
length(test$Prior)
test[test$Predict == profane,]
test[test$Predict = profane,]
profane
?lapply
removeProfane <- function(x){}
?grepl
test[is.element(test$Predict,profane),]
